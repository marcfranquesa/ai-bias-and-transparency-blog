---
author: TAED G2
pubDatetime: 2024-05-27T00:00:00
title: Terminology
slug: terminology
featured: false
description: Collection of terms surrounding bias and explainability in AI and the issues they can cause.
main: true
---

## General Issues

### Artificial Intelligence

Artificial intelligence encompasses engineered systems that utilize computational techniques to perform or automate tasks. This includes machine learning, where systems learn from experience, adapting to new input data and potentially handling tasks previously performed by humans. AI is a branch of computer science focused on creating systems that simulate intelligent behavior in computers, including automated decision-making.

### Bias

Bias in AI can take various forms and come from many sources. Bias in a statistical or computational sense refers to systematic errors or deviations from the true value of predictions, arising from the model's assumptions or input data. In data science, biases are grouped into data bias, design or algorithmic bias, and socio-technical factors that get introduced. The latter lead to systemic prejudice, favoritism, and discrimination against or in favor of certain individuals or groups. Bias can therefore affect outcomes and threaten individual rights and freedoms.

### Fairness

Fairness in AI emphasizes the equitable treatment of individuals or groups in its decisions and actions, ensuring they are consistent and accurate. Each model must determine the most suitable standard of fairness, typically meaning that the AI's decisions should not negatively affect sensitive attributes such as race, gender, or religion, either directly or indirectly.

### Transparency

Transparency in AI means being open and clear about the system's underlying code and processes. It involves making the algorithms, data, and decision-making logic understandable and accessible for review by users, developers, and regulators. Open code transparency helps people understand how AI systems work, builds trust, and promotes accountability by making it easier to spot and address biases and errors.

### Explainability

Explainability refers to the ability to describe or provide sufficient information about how an AI system generates a specific output or arrives at a decision in a specific context. Explainable AI (XAI) is important in maintaining transparency and trust in AI.

### Accountability

Accountability refers to the duty and responsibility of AI system creators, operators, and regulators to ensure the system functions ethically, fairly, transparently, and in compliance with relevant regulations (see fairness and transparency). It ensures that the actions, decisions, and outcomes of an AI system can be traced back to the responsible entity.

### Culpability

Culpability pertains to the degree of blameworthiness or responsibility for wrongful actions or outcomes. In the realm of AI, culpability involves assessing the accountability of various actors, such as developers, operators, and users, for the ethical implications and consequences of AI system behavior. It addresses questions of moral responsibility and liability in cases where AI systems cause harm or perpetuate biases, emphasizing the need to assign accountability and take appropriate corrective measures.

### Responsibility

Responsibility in the context of AI encompasses the obligation and duty of individuals and organizations involved in the development, deployment, and governance of AI systems to ensure their ethical and lawful operation. It entails recognizing the potential societal impacts of AI technologies and taking proactive measures to mitigate risks, safeguard human welfare, and uphold ethical principles such as fairness, transparency, and accountability. Responsible AI practices involve considering the broader societal implications of AI deployment and prioritizing the well-being of individuals and communities affected by AI systems.

### The Black Box

The concept of the "Black Box" comes from the book "The Black Box Society: The Secret Algorithms that Control Money and Information." A Black Box Society is one where governments and institutions closely monitor people, who are unaware of how much personal and non-personal information is being collected, how it is used, and what the consequences will be. Despite sounding dystopian, we can assert that we currently live in a Black Box Society.

## Anthropomorphic Expressions

Anthropomorphic expressions are figurative phrases or terms that exaggerate AI capabilities and performance by attributing human-like traits or characteristics to systems, machines, or abstract concepts that do not possess them. Anthropomorphism can distort moral judgments about AI, such as those concerning its moral character and status, as well as judgments of responsibility and trust. The following expressions humanize some concepts related to bias in artificial intelligence, which might introduce some negative ethical consequences.

### Unfair Agent

Used widely in reinforcement learning and fairness evaluation, this term conveys that the AI makes decisions or takes actions that are not equitable or just. The problem is using a human adjective and using any other would be incorrect also. One possible solution is to create new vocabulary to refer to AI systems.

### Data Prejudice

This term implies that the AI system harbors biases akin to human prejudices, suggesting that the system has formed opinions or biases in the manner of a human. This anthropomorphism can obscure the fact that biases in AI arise from data and algorithmic processes, not personal or subjective experiences.

### Algorithmic Conscience

This expression conveys that the AI system possesses a sense of right and wrong, similar to a human conscience. It anthropomorphizes the decision-making capabilities of the AI, implying that it can inherently discern and act upon moral or ethical considerations, which can distort public understanding of AI's operational nature and limitations.

### Verbal Tenses

Sentences like "the AI system is biased" or "the AI system gives biased answers" are not correct since the system has no being and doesnâ€™t act by itself. These are two examples of misuse of language with the intention of making AI more related to human behavior. Instead, one possible correction is "the user produced biased answers using an AI system." The user must always be who does the action.

## Explainable Artificial Intelligence (xAI)

### AI with a Conscience

This phrase personifies AI systems as having human-like qualities of conscience and ethical awareness, implying they can explain their decisions in a morally sound manner. This suggests that the AI can clearly articulate the reasoning and provide explanations for its actions and decisions, similar to a person justifying their behavior.

### AI with Transparency

This expression personifies AI systems as being open and clear about their workings, much like a transparent person who hides nothing. This implies making the internal reasoning of AI transparent and comprehensible, making them clearer and easier to understand, similar to explaining someone's thought process.
