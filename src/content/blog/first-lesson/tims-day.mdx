---
author: TAED2
pubDatetime: 2024-04-11T00:00:00
title: Tim's Day
slug: first-session/tims-day
featured: true
description: Here we'll go over events in Tim's day that have been affected by bias.
main: false
---

import { SITE } from "@config";

You will recall from previous sections of the blog that nearly 50% of the students who answered our quizz claimed to have never encountered a biased system, but is it really so? Or are we simply not aware of the presence of bias in everything around us?

We will try to answer this question in a practical way, with facts. That's why we introduce you to Tim, someone like any of us: he enjoys hanging out with his friends in the afternoon, going to dinner with his family, etc. We will begin by accompanying him in his daily life, observing possible biases present in some of the activities he may engage in.

It's the weekend, and Tim wakes up in the morning. After breakfast, he decides to start working on one of the assignments he has to submit later that day, as he hasn't made much progress on it yet. After a while, he comes up with an idea to solve one of the final exercises, but he decides to call a friend for some sort of confirmation. After talking for a while with his friend, who explains that he solved the exercise in a different way, his friend mentions to Tim that he has spoken with several people from the class who have also done it using this alternative way. Tim, realizing that time is running out to submit the assignment, quickly searches the internet and finds a link supporting his friend's idea. As soon as he finds this information, he decides to abandon his idea and solve the exercise as he has been told.

<img
  src={SITE.base + "/day/link1.png"}
  alt="pic"
  className="max-w-96 mx-auto"
/>

Now try and answer the following question. Recall the different types of groups in which we can classify bias. Taking this previously mentioned scene, in which group would you classify the bias that appears in this scene?

(_Answer at the end of the blog article_)

Well, after finishing the work, Tim's older sister enters his room. Tim, who is already more relaxed after finishing the task, starts talking to his sister, and in the midst of the conversation, he explains to her what had just happened. His sister, fortunately having taken TAED1 at GCED, tells him that his response had been influenced by the actions of others and explains the importance of being aware of our actions and the biases we may face in our daily lives.

Tim, who doesn't quite see why what he did is questionable, justifies himself by saying that he made sure to search for information on the internet before solving the exercise as he was told by his friend. However, his sister, who knows him better than anyone else, already suspects that his search might not have been entirely thorough and asks him about the information he used. Tim grabs his computer and shows her what he had searched for, and at the moment he showed her the computer, his sister started laughing. Pointing out various links on the computer, she asked him if he had gone past the first link. It turns out that Tim, convinced to solve the exercise as he was told, abandoned the search as soon as he found a link confirming what he thought. What he didn't know was that the following links stated that that method was incorrect. Unfortunately, it was too late, Tim had already submitted the work, and no new submissions were accepted.

<img
  src={SITE.base + "/day/link2.png"}
  alt="pic"
  className="max-w-lg mx-auto"
/>

_Note: Someone might be wondering now: Okay, but if I'm doing an exercise and I have an idea but I'm not sure if it's the solution, can't I ask classmates to avoid being influenced by possible biases? Well, if it's an exam, no! But for other cases, with this presentation, we don't want to convey that message. Our goal is for you to be able to identify the different biases that are present in our daily lives. In this case, what we want to convey is that whenever you encounter any of these biases, be aware of their presence. Regarding this case, even if you ask for help, don't completely abandon your ideas, without letting yourself be carried away by various cognitive biases like the ones we just presented._

_(Answer to the previous question: Tim has acted under a cognitive bias, a type of bias that we can classify in the group of socio-technical biases. Cognitive bias is a systematic error in thinking that occurs when we process and interpret information from our environment in a way that affects the judgments and decisions we make. In fact, in this specific case, we find two different types of cognitive biases present.)_

<br class="pt-5" />

As Tim mulls over the conversation with his sister, he questions how he allowed himself to be influenced so easily, without a moment's doubt. Despite feeling uneasy about it, he decides to continue on Google's website searching for information on those pages that develop his initial idea.
He spends quite some time there, navigating from one publication to another and clicking on links that seem interesting or catch his attention. It's not until his younger brother enters the room to bother him that he realizes the topic of the web pages has been changing over time, and now he's reading a news article explaining that the Taliban are working to restrict the use of Facebook in Afghanistan.
He often loses track of time by clicking on links recommended by Google, but in this specific case, he is surprised because he doesn't understand the connection between his work and the Asian country. His curiosity is so strong that he completely ignores his brother, who, not getting the expected reaction, decides to leave.
Out of inertia, Tim goes to the image search engine, and all he sees are images related to war, oppression, the Taliban, etc., that the country is suffering from. He's surprised because, despite being aware of the current Afghan situation, he doesn't understand this fixation on the theme of the images. How can a country only be recognized for this? Doesn't it have anything else representative? He remembers hearing once that there are languages with few resources, and although he doesn't think Spanish is one of them, he thinks that maybe if he searches in English, the result will be different because there is more information available in that language.

<div>
  <img
    src={SITE.base + "/day/google-search.png"}
    alt="pic"
    className="max-w-lg mx-auto"
  />
  <p class="text-center">
    Image extracted from Google search engine, search in Spanish
  </p>
</div>

He was not heading in the wrong direction, because the photographs that appear vary, showing more diverse content. Although what predominates remains the same, now there are also maps, flags, emblems, and even some landscapes and monuments. Is language such a determining factor? Tim had never been aware that content availability was so relevant, or that the language used to describe the images and their associated metadata could lead to different sets of images. (Note to the reader: we are facing a case of Language bias, where the language of the query can result in different sets of results depending on the availability of content in each language (low-resource languages are not well represented).)

<div>
  <img
    src={SITE.base + "/day/google-search-english.png"}
    alt="pic"
    className="max-w-lg mx-auto"
  />
  <p class="text-center">
    Image extracted from Google search engine, search in English
  </p>
</div>

Highly intrigued by his recent discoveries, he decides to try other search engines while continuing in English to facilitate a better comparison. He starts with Bing, and to his surprise, he finds that in this case, the proportion of war-related images is even lower, a result very similar to what Ecosia offers.

<div>
  <img
    src={SITE.base + "/day/bing.png"}
    alt="pic"
    className="max-w-lg mx-auto"
  />
  <p class="text-center">
    Image extracted from Bing search engine, search in English
  </p>
</div>

<div>
  <img
    src={SITE.base + "/day/ecosia.png"}
    alt="pic"
    className="max-w-lg mx-auto"
  />
  <p class="text-center">
    Image extracted from Ecosia search engine, search in English
  </p>
</div>

Tim was left puzzled. Why is there so much difference if the query is the same? He couldn't make sense of it. He sought out his older sister to ask her what she knew about search engine recommendation systems. She responded that she had studied them superficially, but even so, she couldn't specify much because each one uses a different algorithm, and they don't disclose the algorithm used to prevent manipulation. She also commented that they only say that popularity, relevance, and quality of images displayed are prioritized, but of course, this lack of information creates a transparency issue for the user, who might feel deceived. His sister threw him a question: should a new parameter be added to consider biases in the underlying data? Of course, Tim responded, he wouldn't want his little brother to search for Afghanistan on Google without any context and without cross-checking information from other sources, inadvertently having the application perpetuate, amplify, or create biases. (_Note to the reader: This type of issue is known as **Algorithmic bias**, as search engines prioritize images based on popularity, relevance, and quality, and if they are not designed to consider biases in the underlying data, they can inadvertently perpetuate or amplify existing biases._)
Remembering that his translator mother had spoken to him more than once about search engines in other countries, he decided to try his luck and see what he could find.
Naver in South Korea showed a predominance of war-related images, and Baidu in China displayed a very neutral set, so much so that it made you reconsider what they were really showing you.

Remembering that his translator mother had spoken to him more than once about search engines in other countries, he decided to try his luck and see what he could find.
Naver in South Korea showed a predominance of war-related images, and Baidu in China displayed a very neutral set, so much so that it made you reconsider what they were really showing you.

<div>
  <img
    src={SITE.base + "/day/naver.png"}
    alt="pic"
    className="max-w-lg mx-auto"
  />
  <p class="text-center">
    Image extracted from Naver (South Korean search engine), search in English
  </p>
</div>

<div>
  <img
    src={SITE.base + "/day/baidu.png"}
    alt="pic"
    className="max-w-lg mx-auto"
  />
  <p class="text-center">
    Image extracted from Baidu (Chinese search engine), search in English
  </p>
</div>

A MARCA magazine cover? A hacker? Since when does Afghanistan have a sea? A Japanese temple? The Taj Mahal?... Considering the context of the country he has, Tim can start to understand that if certain cultural groups or international information aren't well represented on the web, then they won't be well represented in image searches either, leading to an imposed limitation of knowledge, explicitly or implicitly biasing the user according to a certain criterion. (_Note to the reader: Here we encounter **Representation and Cultural bias**, where some sociodemographic groups may appear overrepresented or underrepresented due to the prevalence of images on the web (for reasons unrelated to the user), thus reinforcing stereotypes._)
Finally, using Yandex in Russia, he gets images completely opposite to those from all the previous search engines. All the photos are of landscapes, and there's no indication of recent wars in the country's history.

<div>
  <img
    src={SITE.base + "/day/yandex.png"}
    alt="pic"
    className="max-w-lg mx-auto"
  />
  <p class="text-center">
    Image extracted from Yandex (Russian search engine), search in English
  </p>
</div>

Now he's even more puzzled—why? He remembers his sister mentioning that search results are personalized based on the user's past behavior, but he had never used those search engines before. Why is there such a difference? (_Note to the reader: Tim is referring to **Personalization bias**, where results are tailored based on the user's location, search history, past behavior... this can create filter bubbles where users are mainly exposed to content that aligns with their existing preferences and biases._)

Are they biased based on location or political ideologies? It's quite clear that the images that appear must have some reason behind them, since they all redirect you to real web pages in the search engine. But why are certain themes more recurrent while others require scrolling much further down to find? Well, doesn't it seem a bit curious that on the Russian search engine, the majority of the photographs are landscapes and only one shows soldiers with weapons? Why are we shown this specific content that reinforces a certain stereotype? What is the real reason they don't want to show us the algorithm? Are my preferences being represented or is there bias external to me? These and many other questions keep arising.

This should be regulated somehow, Tim thinks. We're in the society of the click, where information enters our eyes at a constant speed and rhythm, and we want more of it instantly. He recalls the popular saying his grandmother often repeated to him, "A picture is worth a thousand words", and he couldn't agree more. It makes sense that bias in images is psychologically more potent because it's what we're accustomed to consuming and the way we retain more information.

Digging deeper, he finds another article mentioning that Google updates its algorithm periodically to try to avoid certain dips in searches. He finds this a good interim solution, as it attempts to improve the user experience and shows they're addressing the issue. However, regardless of whether they represent a diversity of perspectives on the search topic or not, there are always factors like image titles, alternate text, surrounding context, and engagement that increase the likelihood of gaining more visibility and presence. (_Note to the reader: This is the definition of **Relevance and Copyright bias**._)

He drops the subject because he doesn't see an easy solution unless all parties involved are committed to improving it. He's content with having discovered the issue, being aware of the problem, and not just fixating on the stomach-churning images of Afghanistan. At lunch, he'll explain to his family what he's discovered so they can also be aware.

But after the debate sparked at lunch, he's even more worried. What will happen now with AI-generated images? He's fairly certain the problem will only get bigger, but he decides it's enough for today and he'll look into it another day.

<br class="pt-5" />

After a long day, Tim wants to unwind by browsing social media. He starts by opening Twitter (X) and comes across the following post: Haaland to FC Barcelona next season. As much as he would love for it to be true, it clearly seems impossible given the club's current situation. But what if it were true? The post has thousands of likes and interactions, which is likely why it appeared on his feed even though he doesn't follow the journalist. Curious, he visits the journalist’s profile to better understand who broke this news. As expected, he turns out to be a sensationalist journalist known for fake news, yet worryingly, with many followers. One thing is clear: sensationalism on social media gains visibility because more people react to it, and it is favored by the algorithm. But should it really be this way? Wouldn't Tim prefer to read reliable posts that don't just aim to go viral?

Clearly, Twitter already knows that Tim is a Barça fan. And so do the tweeters and their opinions that appear on his feed. After Barça's one-goal victory over Real Madrid in the last match, many people are discussing a controversial play where a player from the opposing team fell in the box, but the referee didn't call a penalty. The tweets appearing on Tim's feed include images and perspectives trying to justify that it was a clear penalty, as they are all written by Barça fans. Seeing various images, Tim thinks, "Why didn't the referee call that? It was obvious, another robbery by Madrid." Wanting to be objective and unbiased, Tim searches for more images until he finds the perspective available to the referee from the video assistant referee (VAR) room. This new angle makes it unclear whether it should have been a penalty. The decision might have been different with another perspective; perhaps the referee would have called the penalty. Now Tim better understands what happened and why the penalty wasn’t given, even though he disagrees with the referee’s decision, he realizes it’s all a matter of perspective.

<div class="mx-auto flex flex-wrap justify-center">
  <div class="justify-center px-10">
    <img src={SITE.base + "/day/foot1.png"} class="max-w-56" alt="pic" />
  </div>
  <div class="justify-center px-10">
    <img src={SITE.base + "/day/foot2.png"} class="max-w-96 px-10" alt="pic" />
  </div>
</div>

Finally, Tim spends some time browsing Instagram. When he gets tired of using it, he notices that he hasn't seen any images of the recent attack at Crocus City Hall in Krasnogorsk, Russia. If he searches, he can find images and videos, but all are protected by a sensitive content warning before viewing. Due to the sensitivity of the images, they have been filtered by the platform’s algorithms, making them not appear in Tim’s recommendations. But to what extent does this censorship serve to protect the population? When does it become misinformation? An event of such current relevance and social and political impact should be visible in any user’s feed. Content moderation filters are important for a social network where anything can be uploaded. But do you think, for example, that the content moderation on Weibo, the Chinese social network, is the same as in the Western world? Interested in this, Tim searches for news about censorship on Weibo and finds that the Chinese government has fined companies responsible for censorship, considering their efforts insufficient. Tim did definitely not expect this as, as far as he knows, Chinese socials have a much stricter content regulation policy, but still it seems insufficient to the government. Could content filters be influenced by specific ways of thinking and biases?

<br class="pt-5" />

It’s the end of the day and Tim finds his parents tuning into the news during dinner time. Today, Tim is particularly attentive, aware of the biases that could influence how the news is presented. As the TV news begins, Tim encounters several situations that make him reflect on the biases present.

The broadcast starts and, after a brief summary, it delves into political news. They begin with national politics, specifically discussing the recently released state budgets. While the TV news displays the amounts allocated to each autonomous community, Tim feels that the message being conveyed is that Catalonia has been allocated more funds than it should have. This surprises Tim because in the morning he had read the newspaper and got the opposite impression. Therefore, he decides to research the topic further, consulting various Catalan and Spanish newspapers.

<div className="flex justify-center">
  <img
    src={SITE.base + "/day/news1.png"}
    class="max-w-48 h-auto px-4"
    alt="news1"
  />
  <img
    src={SITE.base + "/day/news2.png"}
    class="max-w-48 h-auto px-4"
    alt="news2"
  />
  <img
    src={SITE.base + "/day/news3.png"}
    class="max-w-48 h-auto px-4"
    alt="news3"
  />
</div>
<div className="flex justify-center">
  <img
    src={SITE.base + "/day/news4.png"}
    class="max-w-48 h-auto px-4"
    alt="news4"
  />
  <img
    src={SITE.base + "/day/news5.png"}
    class="max-w-48 h-auto px-4"
    alt="news5"
  />
</div>

{/* AAAA */}

Tim realizes that Catalan newspapers tend to express disagreement with the state budgets, believing that Catalonia should receive more funds. In contrast, Spanish newspapers also express disagreement but for the opposite reason: they believe Catalonia has received too much money. This illustrates a case of political bias, where depending on the region of the media outlet, events are explained with specific interests, greatly influencing the selection and interpretation of information.

Next, they discuss the COVID-19 pandemic and its economic impact. Tim notices how the presenter emphasizes the number of businesses that have had to close due to the pandemic and consequently, the significant increase in unemployment in the country. However, Tim's uncle owns an e-commerce business and always mentions to Tim the pandemic's importance for the economic development of his company. This leads Tim to notice that there is too much emphasis on the negative aspects brought about by the pandemic, and the positive aspects, such as recovery funds or the mention of sectors that have thrived, are not mentioned.

This could be a case of sensationalism and commercial bias, where only the cases of those affected are explained, dramatizing the situation to attract more viewers and increase their follower base.

Finally, they move on to science and technology news. It's noticeable that, as has been happening lately, the main topic discussed in the technology section is AI. In today's case, the TV news talks about a new company that has developed AI technology to improve online security. The benefits are highlighted, such as the ability to detect and prevent online scams more effectively. However, there is no mention of the potential issues with user data management, possible errors or biases in AI algorithms, or the ethical implications of using this technology in online surveillance.

This could be a case of competition bias, as there might be a desire to promote and invest heavily in the AI sector, thus only showing the positive aspects and concealing the negative ones.

Overall, Tim is now aware of the amount of biases that are present in their daily life. While recognizing that biases are an inevitable part of life, he endeavors to merely acknowledge them without allowing them to sway his actions or decisions.

<a href={SITE.base + "/posts/first-session/tims-life"}>
  <img
    src={SITE.base + "/young-tim.png"}
    class="mx-auto max-h-60 w-auto"
    alt="tim"
  />
  <p class="text-center">Go to Tim's Life</p>
</a>
