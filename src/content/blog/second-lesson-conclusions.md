---
author: TAED G2
pubDatetime: 2024-04-25T00:00:00
title: Second Lesson Conclusions
slug: second-lesson-conclusions
featured: False
description: Conclusions from each group taken from our second lesson.
main: true
---

# Second Lesson Conclusions

Our plan for the second lesson was to make up a case to make our classmates think about AI bias, explainability and transparency more deeply and broadly. To do so, we had several meetings to come up ourselves with some pointy topics and the expected outcome of the activity.

1. We identified multiple biases that need further definition. The case study for the activity is complex, requiring participants to dissect it to uncover biases.
2. The question of who is to blame for biases arose: is it individuals or institutions?
3. Transparency is important for accountability but can limit technology. Algorithms often lack transparency, leading to unawareness about their operations. Public rules can lead to exploitation of the system, while non-transparency can prevent gaming the system. We need to discuss the balance between transparency and technological advancement.
4. There is a distinction between the explainability of code and transparency. We must assess the impact of making rules public and how resources affect access and fairness.
5. We discussed the concept of neutrality in technology and its implications. For example, a pen is not neutral as it was created within a societal context that values written language. We need to recognize that technology inherently serves specific purposes and is not value-free.
6. Discussions should cover potential different outcomes and ethical considerations of actions. Activities should prompt classmates to consider various perspectives and ethical arguments.

This was the case we presented:

> The case revolves around a credit application. A person, whom we will call **the applicant**, applies for a loan at a bank. Among other requirements, to ensure the repayment of the loan, the **bank** asks about the applicant's health status. Since the applicant reports having cancer, the bank, following protocol, requires a test to be carried out using an algorithm that predicts the severity of cancer patients. This test is performed by a **company** subcontracted by the bank. The applicant takes the test.

> A few days later, the applicant receives a notification that their loan has been denied. The bank processes applications using a predictive algorithm that utilizes various parameters. The applicant requests information from the bank about which parameters were involved in the decision. One of the inputs is the prediction of the severity of the applicant's cancer, and the medical algorithm concludes that it is a high-severity cancer. The applicant visits **their doctor** to verify the result, and the doctor disagrees with the conclusion. With the doctor's opinion, the applicant returns to the bank to contest the loan denial. However, the bank explains that the algorithm processes many more input data points combined through a very sophisticated neural network, and thus, their health status might not have been a determining factor in the decision. Furthermore, the bank points out that the applicant's financial history is not spotless. Simultaneously, the bank asks the company that makes the medical predictions to review the applicant's case, and they respond that the algorithm's output is a strange result considering the data and that they cannot provide a robust explanation for the result.

Then we opened a round of questions and when all were answered we joined them in groups of 6 and aimed for discussion. During the activity we used material we had previously prepared to ensure we covered the following topics:

1. _Bias: What It Is and Why It Arises_
2. _Structural and Social Problems, Socioeconomic Issues. Vulnerability._
3. _Postconventional Ethics_
4. _Responsibility and Blame: What Impact Can It Have?_
5. _Purpose: A Goal Chosen Through Will._
6. _Neutrality_
7. _Transparency. Explainability. Is It Desirable?_

This are the main conclusions reached by each group

## Group 1

The group's conclusions encompassed various ethical and practical considerations regarding the use of algorithms, particularly in banking and healthcare contexts. They identified biases inherent in algorithms, stemming from both data inadequacies and human biases during algorithm development. Discussions highlighted structural and social problems, acknowledging that certain demographic data, while possibly biased, should still be considered in algorithmic decision-making. The group grappled with post-conventional ethics, recognizing its challenges within a capitalist framework and societal norms. They explored the concepts of responsibility and blame, emphasizing the need for awareness of biases and accountability among algorithm developers and data providers. Additionally, they reflected on the purpose of technology, recognizing its potential to exacerbate societal inequalities. The debate centered on the ethical implications of prioritizing bank profits over societal needs, underscoring the complex interplay between financial interests and ethical principles. Ultimately, the group emphasized the importance of transparency, accountability, and consensus-building to navigate the ethical complexities inherent in algorithmic decision-making.

## Group 3

The group explored biases in various contexts, highlighting the inherent challenges in algorithmic decision-making. They debated whether biases were introduced intentionally or unintentionally and whether transparency in algorithmic architectures could mitigate these biases. Some argued that transparent architectures could lead to better understanding and detection of biases, while others expressed concerns about the complexities of transparency and its potential to exacerbate inequalities. Discussions also delved into the ethical implications of introducing biases for personal or organizational gain, raising questions about manipulation and fairness. The group recognized the need for careful consideration of transparency, accountability, and inclusivity in the development and deployment of algorithms to mitigate biases and promote ethical decision-making.

## Group 4

The group discussed whether biases exist in algorithms, particularly concerning factors like the neighborhood a person lives in. They debated whether these biases should be considered and concluded that managing how loans are granted might outweigh any potential biases. While acknowledging the need for indicators to grant loans, they debated whether certain data, such as medical history, is necessary, especially if an applicant has a solid financial history. However, they agreed that filtering data is essential for loan approval. Responsibility for using the algorithm was attributed to both the bank and the engineers. They agreed that lack of transparency cannot justify biases and that the final decision should rest with a medical professional rather than solely relying on AI. They discussed potential discrimination and socioeconomic factors affecting loan approvals. They debated how to avoid discriminating against certain populations and highlighted the importance of using non-discriminatory variables. The group debated the social responsibility of banks in managing risks and suggested redirecting some profits to support social causes. They explored the biases introduced by algorithms versus human decision-making. Some argued that human decisions could introduce additional biases. They emphasized the need for transparency and explainability, especially concerning sensitive medical data used in loan decisions. The use of medical data was debated for its potential to improve algorithm precision versus ethical concerns about privacy and discrimination. They concluded that consensus is needed on when and how to use medical data in loan decisions, involving stakeholders in the decision-making process.

## Group 5

The group delved deeply into the concepts of systematic error, responsibility, and purpose in the context of algorithmic decision-making. They discussed whether biases stemmed from a predetermined impartiality or specific interests. Lack of transparency was pointed out as a possible exacerbator of biases, while bias detection was deemed more feasible when models are explainable. There was debate around responsibility and culpability in algorithm usage, with an emphasis on the need to consider consequences and potential impacts on individuals. Finally, the purpose of new technologies and their potential to amplify inequalities was questioned, highlighting the importance of ethical reflection in the development and use of technology.

## Group 6

In their discussion, the group delved into the complexities of biases, particularly in algorithmic decision-making processes. They explored how biases can manifest through various factors, including data collection methods, economic interests, and individual experiences. Moreover, they debated the allocation of responsibility and blame, ultimately emphasizing the crucial role of banks in ensuring ethical decision-making, especially concerning loan approval processes. Additionally, they grappled with the notion of technology neutrality, concluding that even seemingly neutral algorithms can harbor biases. Finally, they engaged in a nuanced discourse on transparency, weighing the benefits of explainability against the potential drawbacks of full transparency in algorithmic systems. This multifaceted discussion underscores the intricate ethical considerations inherent in the intersection of technology, finance, and societal values.

## Group 7

In their discussion, the group touched on various biases prevalent in societal and business contexts, ranging from media coverage of events like the October 1st incident to biases in loan approval processes, particularly concerning individuals with medical conditions like cancer. They dissected the role of biases in algorithmic decision-making, considering factors like data collection methods and business interests. Additionally, they explored the concept of vulnerability, emphasizing the influence of societal context on business decisions and the need for ethical considerations in algorithm design. Furthermore, they delved into the nuances of responsibility and culpability, debating the extent to which banks should be held accountable for algorithmic decisions. The conversation also delved into the purpose of technology, ethical considerations surrounding transparency and explainability in algorithmic systems, and the ethical dilemmas inherent in lending practices. Ultimately, their discussion underscored the complexity of balancing business interests with ethical considerations in the age of technological advancement.
