---
author: TAED G2
pubDatetime: 2024-05-30T00:00:00
title: Whistleblowing Guide
slug: whistleblowing-guide
featured: true
description: A guide for those who want to report bad practices regarding AI.
main: true
---

# Whistleblowing Guide

The term **whistleblowing** has increased in use in recent years, as awareness of rights and the importance of ethical behavior within organizations has grown. Additionally, a legal framework for the protection of so-called **whistleblowers** has been developed in parallel.

Whistleblowing refers to the act of reporting misconduct, illegal activities, or unethical behavior within an organization to internal or external parties who have the authority or ability to address the issue. This can include exposing fraud, corruption, security violations, environmental offenses, and any activities that violate laws or ethical standards (which may not necessarily be regulated by law).

A whistleblower is a person who reveals information about misconduct occurring within an organization. Often, this is an employee who possesses privileged knowledge about the reported issues. In the context of Artificial Intelligence, this may involve risks that span various fields, including:

- **Security issues:** Data must be well-protected from cyberattacks or misuse.
- **Privacy violations:** improper handling of personal data or concerns about surveillance of users or civilians.
- **Bias and discrimination**
- **Transparency, explainability and accountability.**

In this guide, a specific focus will be placed on the last two points, although the outlined guidelines can be applied to any case of whistleblowing.

Often, the word whistleblowing can be associated with other terms with negative connotations, such as "snitch" or "informant." However, we want to emphasize its importance. Whistleblowing protects public interests and civil rights, helps prevent fraud, and promotes transparency and accountability, consequently improving practices within organizations. In this way, it allows for the exposure of corruption and abuse, while advancing the promotion of human rights. Very often, organizations themselves may not be aware of the practices carried out by their employees.

In the field of Artificial Intelligence, whistleblowing is especially crucial given the impact these technologies can have on society and the lack of awareness users have about them. The role of the whistleblower is vital to ensuring that these technologies are used responsibly and ethically. Moreover, being such a new field, it lacks sufficient regulations and an established model of practices and conduct. This is why it can be easier to cross red lines if they are not clearly defined.

Moreover, we are in the era of Big Tech, with large companies having significant control over resources and the decisions that are made. The role of whistleblowers is vital in holding these large companies accountable for their actions. Currently, tech accountability is limited by a lack of transparency.

Have you detected misconduct within your company? Now what? Probably, many questions are swirling in your head.

1. Who should I inform? What options do I have?
1. Is it worth reporting the wrongdoing? Have there been other cases?
1. How many details/evidence are needed?
1. What kind of protection can I expect? From whom? How and when can I access it?

This guide is designed to help you respond effectively. It includes answers to all the questions you are likely asking yourself and describes the steps you need to take. It also incorporates a series of real cases. For now, we have good news: if you are reading this guide, you are on the right track. As The Tech Worker Handbook declares:

> “Whistleblowing — the act of speaking up in order to improve a situation for others — is an individual decision that should be made after a careful consideration of risks, options, and intended outcomes. My hope, though, is that those who do decide to take great risks in coming forward — for all of us — are better prepared and supported. [1]“

**What might induce me to report a misconduct?**

In general, there is a willful ignorance within the company/work group regarding the existence of biases, which are unfortunately inevitable. However, this does not prevent the need to try to mitigate them as much as possible.

Some more specific red lines for each type of bias:

_Social Bias:_

- The existence of inherent biases is not questioned.
- The general attitude is arrogant and has a closed-minded point of view.
- There is no consultation with ethics committees, multidisciplinary teams, etc.

_Algorithmic Bias:_

- There is no review to see if the algorithm has learned any undesirable behavior.
- The algorithm is not adequately tested.
- There is a priority to put the algorithm into production before verifying its correct functioning.

_Data (Training) Bias:_

- The data source being used is not representative.
- There is no effort to ensure that the data represents reality.
- Training data is not verified.
  Varied data is not used.

**You have detected misconduct within your organization, whom do you inform?**

First of all, you should try to resolve the issue internally. Find out if there is a way to address the problem at a lower level by bringing the misconduct or error to the attention of higher-ups or those who could put an end to it. Most companies or government agencies have internal mechanisms or processes to address illegal conduct. Moreover, all companies with more than 50 employees must have an anonymous channel for reporting all kinds of issues. Figure 1 shows the steps you should follow.

<img src="/whistleblowing-guide/image1.png" alt="To whom do I report to? When?" className="mx-auto" width="450"/>
<p className="text-center"> Figure 1. To whom do I report to? When? (Diagram extracted from [2])

**How do you know if your complaint has been ignored?**

You may not receive any notification of decisions or outcomes following your report. It is recommended to wait approximately 6 months before escalating it to the next level. [2]

However,

If the wrongdoing is being carried out by your superiors,
If you are aware of other whistleblowers in the company who have faced retaliation,
If you are experiencing retaliation from the organization,

Then this step can be skipped, and you should report externally.

What is the next step?
If you have been unable to report internally, or such a report has not yielded results, you will need to make an external report. What steps are essential?

The first step should be gathering evidence. How many details/proofs are needed? If you choose to tell your story, you must obtain evidence to support it; it is not enough to simply narrate the facts, although ultimately, you can always use the argument of **reasonable belief**. Documents, emails, internal memos—collect only the strictly necessary data, especially if it could involve privacy violations. If it is discovered that you have obtained sensitive data unrelated to the case, they could file a complaint against you.

Secondly, seek legal advice from a lawyer. It is important to have someone to guide you through the next steps. There are also lawyers or firms specializing in handling whistleblower cases.

It is vital not to make any posts on social media. Individuals have no protection on social media and this could be used against you later. The law protects whistleblowers who report in the public interest and according to procedures, from various reprisals.

If at any point you need psychological support, seek someone who can assist and accompany you.

Finally, look up more information. The more information you gather, the better decisions you shall make and ask yourself:

**Have there been any other cases?**

One of the previous guidelines underscores the benefits of examining other cases involving whistleblowers. Here, some examples related to biased or non-explainable AI systems are provided, which have played a significant role in exposing various ethical issues over the past few decades.

Firstly, let's consider a recent example. In March 2024, Shane Jones, a senior Microsoft engineer, raised significant concerns about the company's AI image generation tool, Copilot Designer. Jones discovered that the tool could easily produce inappropriate images, including those depicting sex, violence, underage drinking, and drug use, as well as instances of political bias, conspiracy theories, and copyrighted imagery, despite existing safeguards [7].

After reporting these issues internally since December 2023, Jones felt that Microsoft did not take sufficient action. This prompted him to alert the U.S. Federal Trade Commission (FTC) Chair Lina Khan and Microsoft's board of directors, urging an independent review of Microsoft’s AI incident reporting processes and stricter regulatory oversight of generative AI technologies.

This was not the first time Jones spoke out about his concerns. Before contacting the FTC, he made a public post on LinkedIn urging OpenAI to remove DALL-E, the model powering Copilot Designer, from public use. Despite facing pressure from Microsoft's legal team to retract his statements, Jones continued to voice his concerns, even reaching out to U.S. senators about AI safety risks. [8]

Another prominent whistleblower case involves Dr. Timnit Gebru, a former Google researcher and co-leader of Google's Ethical AI team. She was forced out of the company in December 2020 after co-authoring a paper that highlighted the risks of large AI language models, including those developed by Google. These risks included environmental impacts, fairness, and the difficulty of detecting embedded biases. [9]

Just three months after Gebru's dismissal, Google also fired Dr. Margaret Mitchell, the founder of the Ethical AI team, because she had sent a document to Google’s public relations department questioning the company’s reasons for firing Gebru.

This led to widespread criticism of Google, which appeared to be silencing and dismantling the entire Ethical AI team. The incident sparked debates about the treatment of researchers, the ethical development of AI, and the transparency of big tech companies. Gebru now advocates for stronger protections for AI researchers to ensure they can safely report and address these biases while maintaining their freedom to critique their own technologies [10].

Finally, we might also highlight another famous whistleblower, perhaps the foremost example of a tech worker revealing crucial information: Frances Haugen. In late 2021, Haugen shed light on how Facebook prioritized profits over safety and knowingly spread disinformation. Her revelations brought to public attention the dangers posed by Facebook's algorithms and how they manipulate users, influencing public opinion and behavior [11].

But there have been many others, and there will likely be quite a few more in the coming years if current trends continue.

**What kind of protection can I expect? From whom?**

Legal protection for whistleblowers may vary widely from country to country. In 2019 the European Parliament and the European Council passed the Directive (EU) 2019/1937 [3], which states that “Common minimum standards ensuring that whistleblowers are protected effectively should apply as regards acts and policy areas where there is a need to strengthen enforcement”. The directive prohibits retaliation against whistleblowers, safeguards their identities and offers several reporting avenues. It should be noted that it is not a regulation but a directive. A "directive" is a legislative act that sets out a goal that EU member states must achieve. However, it is up to the individual countries to devise their own laws on how to reach these goals. [4]. Therefore, it is imperative to look into the specific regulations of your country.

The following map portrays the progress made by each of the EU countries since the directive was passed.

The EU also published a report which describes the changes made from 2019 to 2021. [5]

<div className="flex flex-wrap mx-auto gap-10 justify-center">
<img src="/whistleblowing-guide/image2.png" width="350">
<img src="/whistleblowing-guide/image3.png" width="350">
</div>
<p className="text-center">Legislation in countries before and after the EU directive (2019 VS 2021). [6]</p>

In Spain, recent changes were made, more in particular the Law 2/2023, of February 20, regulating the protection of persons who inform about normative and corruption fighting infractions [6].

**How to prevent bias?**

These are the best practices to minimize the introduction of bias in AI models and algorithms from the outset.

Biases can arise in many different forms. They exist in data, algorithms, and even inherently in our society (such as cognitive biases), and all these stem from our nature and behavior. As data scientists, addressing biases is a crucial consideration throughout the entire analysis process, and we must take measures to mitigate them whenever possible. We need to be clear about several aspects: What should we do? How should we do it? What must we avoid? What challenges do we face?

In our case, addressing bias requires a combination of:

- careful data collection, including diverse and representative datasets
- rigorous and impartial analysis and measurement techniques
- addressing any potential gaps or limitations found, incorporating bias reduction techniques during the modeling process, and fairness-aware algorithms
- and always considering relevant ethical implications

Proactively addressing bias is essential for mitigating its impact on analysis and any decisions based on it, while also contributing to more accurate, reliable, and fair outcomes. Here are some approaches that can be taken:

**1. Use Diverse Datasets**

Ensure datasets accurately represent the population or phenomenon being analyzed. Include a wide range of demographics, geographic regions, and other relevant factors to avoid sampling bias.

**2. Apply Statistical Techniques**

Use statistical or processing methods to reduce potential bias in data that couldn't be avoided earlier. For example, implement stratified sampling by dividing data into subsets based on common characteristics to ensure proportional representation. Alternatively, use augmentation methods to balance class distributions.

**3. Select Fairness-Aware Algorithms**

Choose algorithms specifically designed to mitigate bias and promote fairness. Fairness-aware machine learning, an emerging field, aims to minimize bias by explicitly considering fairness criteria during model training and evaluation. Techniques include:
Quantifying model fairness by measuring prediction disparities between different groups.
Modifying training data to reduce bias before training.
Adding fairness constraints to algorithms, such as fairness regularization terms in the loss function or optimization process adjustments to balance fairness and accuracy.
Adjusting or calibrating predictions based on certain criteria.

**4. Conduct Audits and Evaluations**

Perform comprehensive audits and evaluations of your data and models to identify and quantify bias. This involves analyzing the demographic composition of your dataset, measuring the disparate impact of your models on different groups, and evaluating model fairness using metrics like equal opportunity or demographic parity.

**5. Perform Sensitivity Analyses**

Evaluate the robustness of your conclusions by considering potential sources of bias. Systematically vary input parameters or assumptions in your analysis to assess their impact on results. This helps understand the sensitivity of conclusions to potential bias and identify areas needing additional mitigation efforts.

**6. Collaborate in Interdisciplinary Teams**

Work with interdisciplinary teams, including ethicists, domain experts, and stakeholders, to assess the ethical implications of your analysis. Ensure that bias mitigation efforts align with ethical principles and standards. This review and oversight help identify blind spots and unintended consequences.

By implementing these strategies, you can better address bias, leading to more equitable and trustworthy AI and machine learning outcomes.
Using Fairness-Aware Machine Learning as a reference, we can conclude that by ensuring fairness, transparency, and accountability, we can build models that positively impact society and reduce existing inequalities. However, it is crucial to carefully consider the associated challenges and ethical considerations, such as defining fairness, balancing it with accuracy, and avoiding unintended consequences, to ensure that these models are truly fair and unbiased.

## References

[1] _The Tech Worker Handbook._ (n.d.). https://techworkerhandbook.org/

[2] The Council of Europe (June 2019). _Protection of Whistleblowers._ Handbook. Project against Economic Crime (PECK II). https://www.coe.int/peck2

[3] Directive - 2019/1937 - EN - _eu whistleblowing directive_ - EUR-Lex. (n.d.). https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32019L1937

[4] _Types of legislation | European Union._ (n.d.). European Union. https://european-union.europa.eu/institutions-law-budget/law/types-legislation_en

[5] _Transparency International (2021)._ ARE EU GOVERNMENTS TAKING WHISTLEBLOWER PROTECTION SERIOUSLY?
2021_EU-Governments-Whistleblower-Protection_English_12052021.pdf

[6] BOE-A-2023-4513 Ley 2/2023, _de 20 de febrero, reguladora de la protección de las personas que informen sobre infracciones normativas y de lucha contra la corrupción._ (n.d.). https://www.boe.es/buscar/act.php?id=BOE-A-2023-4513

[7] Microsoft whistleblower sounds alarm on offensive, harmful imagery generated with help of OpenAI tool. (2024, March 7). Fortune. https://fortune.com/2024/03/06/microsoft-whistleblower-openai-offensive-harmful-images-copilot/

[8] Ajao, E. (2024, March 7). Microsoft whistleblower, OpenAI, the NYT, and ethical AI. Enterprise AI. https://www.techtarget.com/searchenterpriseai/news/366572699/Microsoft-whistleblower-OpenAI-the-NYT-and-ethical-AI

[9] Change, G. W. F. R. (2022, January 7). The future must be ethical: #MakeAIEthical - Google Walkout for Real Change - Medium. Medium. https://googlewalkout.medium.com/the-future-must-be-ethical-makeaiethical-9eb3edd7cf3c

[10] Ex-Google researcher: AI workers need whistleblower protection | MIT Sloan. (2021, October 6). MIT Sloan. https://mitsloan.mit.edu/ideas-made-to-matter/ex-google-researcher-ai-workers-need-whistleblower-protection

[11] Menczer, F. (n.d.). Facebook whistleblower Frances Haugen testified that the company’s algorithms are dangerous – here’s how they can manipulate you. The Conversation. https://theconversation.com/facebook-whistleblower-frances-haugen-testified-that-the-companys-algorithms-are-dangerous-heres-how-they-can-manipulate-you-169420
