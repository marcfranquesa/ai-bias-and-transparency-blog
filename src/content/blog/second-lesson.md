---
author: TAED G2
pubDatetime: 2024-04-15T00:00:00
title: Second Lesson
slug: second-lesson
featured: False
description: An introduction to our case & the several debate topics.
main: true
---

# Second Lesson

During this second lesson, we have worked on an activity which has allowed us to ponder about some specific, and often philosophical, topics related to bias. In this article we will just comment on the activity planning. Further comments on the results and conclusions obtained through the activity will be given in a later post. To do so, we have designed the following case.

## Case explanation

> The case revolves around a loan application. A person, whom we'll call the applicant, requests a loan from the bank. Among other requirements, the bank, to ensure loan repayment, asks about the applicant's health status. Since the applicant informs that they have cancer, the bank, as per protocol, requires a test that is carried out through an algorithm that predicts the severity of a patient's cancer. This test is performed by a company subcontracted by the bank. The applicant undergoes the test.
>
> After a few days the applicant receives a notification stating that the loan has been denied. The bank processes the applications using a prediction algorithm that uses various parameters. The applicant asks the bank which parameters were involved in the decision. One of the input parameters, among others, is the prediction about the state of the cancer; the medical algorithm concludes that it is a severe cancer. The applicant visits his/her doctor to contrast the result, and the doctor disagrees. With the doctor's opinion, the applicant visits the bank again to contest the loan denial, but the bank informs them that the algorithm receives many more input data that are combined through a sophisticated neural network, and therefore, their health status may not have played a determining role in the decision. Furthermore, the bank argues that their financial history is not spotless. Meanwhile, the bank requests the company that makes the medical predictions to review the applicant's case, and they reply that the output of the algorithm is an unusual result considering the data of the applicant and that they cannot provide a robust explanation of the result.

## Debate topics

Here we list some of the debate topics that might arise when pondering about the previously stated case.

1. Should banks have the **right to ask** for medical data as a necessary condition to approve or deny a loan?
2. Would there need to be a **right to be forgotten** regarding people's financial history?
3. Do all algorithms need to be **explainable**?
4. Do all algorithm architectures need to be **transparent**?
5. Should banks have **total freedom** when defining the criteria under which the approve or deny a loan?
6. Can we solve existing **bias** problems in people's financial profiles?
7. Do approval/denial algorithms contribute with **equity to society**? Or are they developed in a biased way?
8. Who is **guilty**? And **responsible**?
9. Is there any **willful ignorance** behind loan approval/denial algorithm's lack of explainability?
10. Is it ethic that the bank's benefit is set above society's **needs** in loans? Or should anyone have the right to be given a loan?
11. Do algorithms **increase the bias effect** on the belief that some people are more likely to repay a loan?

### Philosophical approaches

This case can also be analyzed in a more philosophical fashion. To be able to understand the inherent philosophical topics that are present in the case, we strongly suggest to dive into the following topics.

1. **Bias**. What is it and where does it come from?
2. Structural and social problems. Socio-economic problems. **Vulnerability**.
3. **Post-conventional ethics**. Analyze and understand the three possible levels of moral development of a person. Here we give you a [link](http://www.xtec.cat/~lvallmaj/passeig/kohlber2.htm) where you can find some information about this topic. 😉
4. **Responsibility and guiltiness**. Who is accountable for the decisions of an algorithm? Which is the impact these decisions can have? What is willful ignorance and when is it present?
5. **Purpose**. How can we choose an end through the will. Who is behind the technology? For what purpose is technology created?
6. **Neutrality**. Technology is NOT axiologically neutral. Are the algorithms employed in the proposed case neutral? What values do they reflect? Who benefits and who is harmed by their use?
7. **Transparency and explainability**. Transparency and explainability as a solution to detect biased algorithms. What are the limits of transparency?

By combining all of the topics above, a deeper understanding on bias and transparency should be developed.
